#!/usr/bin/env python3
"""
äº¬éƒ½åºœå¿ƒéœŠã‚¹ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’Supabaseã®POIã¨ã—ã¦ç™»éŒ²ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆGeometryå¯¾å¿œç‰ˆï¼‰
"""

import csv
import os
import uuid
import json
import sys
from supabase import create_client, Client
from dotenv import load_dotenv
import pygeohash as pgh

# --- è¨­å®š ---
load_dotenv()

SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_ANON_KEY = os.environ.get("SUPABASE_ANON_KEY")
CSV_FILE = 'kansai_ghost_spots/äº¬éƒ½åºœ_ghost_spots.csv'
GEOHASH_PRECISION = 6

# ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆ--test-modeã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼‰
TEST_MODE = '--test-mode' in sys.argv

# ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šã®ãŸã‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
CATEGORY_KEYWORDS = {
    'establishment': [
        'ãƒˆãƒ³ãƒãƒ«', 'ç—…é™¢', 'ãƒ›ãƒ†ãƒ«', 'æ—…é¤¨', 'ãƒ¢ãƒ¼ãƒ†ãƒ«', 'å»ƒå¢Ÿ', 'æ´‹é¤¨', 'å­¦æ ¡', 'ä¸­å­¦æ ¡', 'é«˜æ ¡', 'å¤§å­¦',
        'é§…', 'è¸åˆ‡', 'å•†æ¥­æ–½è¨­', 'éŠåœ’åœ°', 'ãƒˆã‚¤ãƒ¬', 'å…¬è¡†ãƒˆã‚¤ãƒ¬', 'å»ƒ', 'è·¡', 'ã‚¢ã‚¹ãƒ¬ãƒãƒƒã‚¯',
        'æ©‹', 'ãƒ–ãƒªãƒƒã‚¸', 'è½åˆæ©‹', 'èµ¤æ©‹', 'ã‚¯ãƒ¬ã‚¤ãƒ³ãƒ–ãƒªãƒƒã‚¸', 'é“', 'å³ ', 'ã‚«ãƒ¼ãƒ–', 'å±±ä¸­è¶Šãˆ'
    ],
    'natural_feature': [
        'æ¹–', 'æ± ', 'ãƒ€ãƒ ', 'å±±', 'æ£®', 'å·', 'æ»', 'æ¨¹æœ¨', 'æ‰', 'ã‚¯ã‚¹ãƒã‚­', 'æµ·', 'æ·±æ³¥æ± ', 'è¡€ã®æ± ',
        'å¦™è¦‹å±±', 'ç®•é¢', 'ä¿æ´¥å·'
    ],
    'tourist_attraction': [
        'åŸè·¡', 'å¤æˆ¦å ´', 'å‡¦åˆ‘å ´', 'å°†è»å¡š', 'èˆ¹å²¡å±±'
    ],
    'place_of_worship': [
        'ç¥ç¤¾', 'å¯º', 'å¢“åœ°', 'æ…°éœŠç¢‘', 'å¡š', 'å¤§æ˜ç¥', 'åƒæ—¥å¢“åœ°', 'é¦–å¡š'
    ],
    'park': [
        'å…¬åœ’', 'ç·‘åœ°', 'å¾¡è‹‘', 'å††å±±å…¬åœ’'
    ]
}

def determine_categories(name: str, description: str = '') -> list:
    """ã‚¹ãƒãƒƒãƒˆåã¨èª¬æ˜æ–‡ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®šã™ã‚‹"""
    categories = ['horror_spot']
    text = f"{name} {description}".lower()
    
    for category, keywords in CATEGORY_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text:
                if category not in categories:
                    categories.append(category)
                break
    
    return categories

def save_grid_cell(supabase: Client, geohash: str):
    """Geohashã«å¯¾å¿œã™ã‚‹Grid Cellã‚’ä¿å­˜ã¾ãŸã¯å–å¾—"""
    if TEST_MODE:
        print(f"    ğŸ§ª [TEST] Grid Cell {geohash} ã‚’ãƒ†ã‚¹ãƒˆä½œæˆ (ID: 999)")
        return 999
        
    try:
        # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
        existing_res = supabase.table('grid_cells').select('id').eq('geohash', geohash).execute()
        if existing_res.data:
            return existing_res.data[0]['id']

        # æ–°è¦ä½œæˆ - æ­£ã—ã„APIã‚’ä½¿ç”¨
        bbox = pgh.get_bounding_box(geohash)
        # BoundingBoxã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰min/maxå€¤ã‚’å–å¾—
        min_lat = bbox.min_lat
        min_lon = bbox.min_lon  
        max_lat = bbox.max_lat
        max_lon = bbox.max_lon
        polygon_wkt = f"POLYGON(({min_lon} {min_lat}, {max_lon} {min_lat}, {max_lon} {max_lat}, {min_lon} {max_lat}, {min_lon} {min_lat}))"

        grid_cell_data = {
            'geometry': f"SRID=4326;{polygon_wkt}",
            'geohash': geohash
        }
        insert_res = supabase.table('grid_cells').insert(grid_cell_data).execute()

        if insert_res.data:
            grid_cell_id = insert_res.data[0]['id']
            print(f"    âœ… Grid Cell {geohash} ã‚’æ–°è¦ä½œæˆã—ã¾ã—ãŸ (ID: {grid_cell_id})")
            return grid_cell_id
        else:
            print(f"    âŒ Grid Cell {geohash} ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return None

    except Exception as e:
        print(f"    âŒ Grid Cell {geohash} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def insert_poi_with_geometry(supabase: Client, poi_data: dict, lat: float, lon: float):
    """Geometryå¯¾å¿œã®POIæŒ¿å…¥"""
    if TEST_MODE:
        print(f"    ğŸ§ª [TEST] POIæŒ¿å…¥ãƒ†ã‚¹ãƒˆ: {poi_data['name']}")
        print(f"         ä½ç½®: POINT({lon} {lat})")
        print(f"         ã‚«ãƒ†ã‚´ãƒª: {poi_data['categories']}")
        return {'success': True, 'test_mode': True}
        
    try:
        # PostGIS GEOMETRYå½¢å¼ã§ç›´æ¥æŒ¿å…¥
        point_wkt = f"POINT({lon} {lat})"
        poi_data['location'] = f"SRID=4326;{point_wkt}"  # PostGIS GEOMETRYå½¢å¼
        
        result = supabase.table('pois').insert(poi_data).execute()
        return result.data
    except Exception as e:
        print(f"    âŒ POIæŒ¿å…¥ã«å¤±æ•—: {e}")
        return None

def check_duplicate(supabase: Client, name: str, url: str) -> bool:
    """é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåå‰ã¾ãŸã¯URLã§åˆ¤å®šï¼‰"""
    if TEST_MODE:
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯é‡è¤‡ãªã—ã¨ã—ã¦æ‰±ã†
        return False
        
    try:
        # åå‰ã§ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        name_result = supabase.table('pois').select('id', count='exact').eq('name', name).execute()
        if name_result.count > 0:
            return True
            
        # URLã§ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆURLãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        if url:
            url_result = supabase.table('pois').select('id', count='exact').eq('url', url).execute()
            if url_result.count > 0:
                return True
                
        return False
    except Exception as e:
        print(f"    âŒ é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    mode_text = "ğŸ§ª [TEST MODE]" if TEST_MODE else ""
    print(f"--- ğŸ‘» äº¬éƒ½åºœå¿ƒéœŠã‚¹ãƒãƒƒãƒˆç™»éŒ²é–‹å§‹ {mode_text} ---")

    # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯çœç•¥ï¼‰
    supabase = None
    if not TEST_MODE:
        if not all([SUPABASE_URL, SUPABASE_ANON_KEY]):
            print("âŒ ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° SUPABASE_URL ã¨ SUPABASE_ANON_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
        print("âœ… Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–å®Œäº†")
    else:
        print("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: Supabaseæ¥ç¶šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    if not os.path.exists(CSV_FILE):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{CSV_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {CSV_FILE}")

    total_added = 0
    total_skipped = 0
    total_errors = 0

    try:
        with open(CSV_FILE, mode='r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            
            for i, row in enumerate(reader, 1):
                spot_name = row.get('name')
                print(f"\n  [{i}] å‡¦ç†ä¸­: {spot_name}")

                try:
                    lat = float(row['latitude'])
                    lon = float(row['longitude'])
                    url = row.get('url')

                    if not all([spot_name, lat, lon, url]):
                        print("    âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                        total_errors += 1
                        continue

                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    if check_duplicate(supabase, spot_name, url):
                        print(f"    â­ï¸  ç™»éŒ²æ¸ˆã¿ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        total_skipped += 1
                        continue
                    
                    # Grid Cellå–å¾—
                    if TEST_MODE:
                        geohash = f"test_{lat:.4f}_{lon:.4f}"
                    else:
                        geohash = pgh.encode(lat, lon, precision=GEOHASH_PRECISION)
                    
                    grid_cell_id = save_grid_cell(supabase, geohash)
                    if not grid_cell_id:
                        print(f"    âŒ Grid Cell IDå–å¾—å¤±æ•—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                        total_errors += 1
                        continue
                    
                    # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
                    categories = determine_categories(spot_name, row.get('description', ''))
                    categories_json = json.dumps(categories, ensure_ascii=False)
                    print(f"    ğŸ“‹ åˆ¤å®šã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª: {categories}")
                    
                    # POIãƒ‡ãƒ¼ã‚¿ä½œæˆ
                    poi_data = {
                        'id': str(uuid.uuid4()),
                        'name': spot_name,
                        'categories': categories_json,
                        'grid_cell_id': grid_cell_id,
                        'rate': 0.0,
                        'url': url
                    }

                    # Geometryå¯¾å¿œæŒ¿å…¥
                    result = insert_poi_with_geometry(supabase, poi_data, lat, lon)
                    
                    if result:
                        print(f"    ğŸ‘ {spot_name} ã‚’POIã¨ã—ã¦æ–°è¦ç™»éŒ²ã—ã¾ã—ãŸã€‚")
                        total_added += 1
                    else:
                        print(f"    âŒ {spot_name} ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        total_errors += 1
                
                except (ValueError, TypeError) as e:
                    print(f"    âŒ ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒç„¡åŠ¹ã§ã™: {e}")
                    total_errors += 1
                except Exception as e:
                    print(f"    âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
                    total_errors += 1
                    
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«å¤§ããªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return

    print("\n--- âœ… äº¬éƒ½åºœå¿ƒéœŠã‚¹ãƒãƒƒãƒˆç™»éŒ²å®Œäº† ---")
    print(f"âœ¨ æ–°è¦è¿½åŠ : {total_added}ä»¶")
    print(f"â© ã‚¹ã‚­ãƒƒãƒ— (é‡è¤‡): {total_skipped}ä»¶")
    print(f"ğŸš« ã‚¨ãƒ©ãƒ¼: {total_errors}ä»¶")
    print("------------------------------------------")

if __name__ == "__main__":
    main()
