#!/usr/bin/env python3
"""
äº¬éƒ½POIå–å¾—ãƒ»ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ—ãƒ©ãƒ³3ï¼šç„¡æ–™æ æœ€å¤§åŒ–ç‰ˆï¼‰
323å€‹ã®Geohashã€ç´„4,845ä»¶POIã€$173ã§å®Ÿè¡Œ
"""

import requests
import time
import json
import os
import sys
import argparse
from datetime import datetime, timedelta
import pygeohash as pgh
from supabase import create_client
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®š
GOOGLE_MAPS_API_KEY = os.environ.get('GOOGLE_MAPS_API_KEY')
SUPABASE_URL = os.environ.get('SUPABASE_URL')
SUPABASE_ANON_KEY = os.environ.get('SUPABASE_ANON_KEY')

# Supabase ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
supabase = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

# APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
CHUNK_SIZE = 40  # åŒæ™‚å‡¦ç†ã™ã‚‹Geohashæ•°
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’
RADIUS = 1000  # ãƒ¡ãƒ¼ãƒˆãƒ«

# POIã‚¿ã‚¤ãƒ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ–°APIå¯¾å¿œã€æ—¥æœ¬èªå¯¾å¿œï¼‰
POI_TYPES = {
    'restaurant': 'ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³',
    'cafe': 'ã‚«ãƒ•ã‚§',
    'tourist_attraction': 'è¦³å…‰åæ‰€',
    'museum': 'ç¾è¡“é¤¨ãƒ»åšç‰©é¤¨',
    'park': 'å…¬åœ’',
    'shopping_mall': 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«',
    'convenience_store': 'ã‚³ãƒ³ãƒ“ãƒ‹ã‚¨ãƒ³ã‚¹ã‚¹ãƒˆã‚¢',
    'gas_station': 'ã‚¬ã‚½ãƒªãƒ³ã‚¹ã‚¿ãƒ³ãƒ‰',
    'hospital': 'ç—…é™¢',
    'pharmacy': 'è–¬å±€',
    'bank': 'éŠ€è¡Œ',
    'atm': 'ATM',
    'lodging': 'å®¿æ³Šæ–½è¨­',
    'transit_station': 'äº¤é€šæ©Ÿé–¢'
}

def load_plan3_config():
    """ãƒ—ãƒ©ãƒ³3ã®è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    with open('/Users/kaka/dev/Go/Team8-App/script/plan3_execution_config.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def save_progress(data, filename='plan3_progress.json'):
    """é€²æ—ã‚’ä¿å­˜"""
    progress_file = f'/Users/kaka/dev/Go/Team8-App/script/{filename}'
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_progress(filename='plan3_progress.json'):
    """é€²æ—ã‚’èª­ã¿è¾¼ã¿"""
    progress_file = f'/Users/kaka/dev/Go/Team8-App/script/{filename}'
    if os.path.exists(progress_file):
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def search_places_by_type(lat, lon, place_type, radius=RADIUS):
    """Google Places API (New) ã§POIã‚’æ¤œç´¢"""
    url = "https://places.googleapis.com/v1/places:searchNearby"
    
    headers = {
        'Content-Type': 'application/json',
        'X-Goog-Api-Key': GOOGLE_MAPS_API_KEY,
        'X-Goog-FieldMask': 'places.id,places.displayName,places.primaryType,places.location,places.rating,places.userRatingCount,places.shortFormattedAddress,places.photos'
    }
    
    payload = {
        "includedTypes": [place_type],
        "maxResultCount": 20,
        "locationRestriction": {
            "circle": {
                "center": {
                    "latitude": lat,
                    "longitude": lon
                },
                "radius": radius
            }
        },
        "languageCode": "ja",
        "regionCode": "JP"
    }
    
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            places = data.get('places', [])
            
            # æ–°APIå½¢å¼ã‚’æ—§APIå½¢å¼ã«å¤‰æ›
            converted_results = []
            for place in places:
                converted_place = {
                    'place_id': place.get('id'),
                    'name': place.get('displayName', {}).get('text', ''),
                    'geometry': {
                        'location': {
                            'lat': place.get('location', {}).get('latitude'),
                            'lng': place.get('location', {}).get('longitude')
                        }
                    },
                    'rating': place.get('rating'),
                    'user_ratings_total': place.get('userRatingCount'),
                    'vicinity': place.get('shortFormattedAddress', ''),
                    'photos': [{'photo_reference': photo.get('name', '')} for photo in place.get('photos', [])]
                }
                converted_results.append(converted_place)
            
            return converted_results
            
        except Exception as e:
            print(f"Request failed (attempt {attempt + 1}): {e}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY * (attempt + 1))
            else:
                return []
    
    return []

def get_pois_for_geohash(geohash):
    """æŒ‡å®šã•ã‚ŒãŸGeohashã‚¨ãƒªã‚¢ã®POIã‚’å–å¾—"""
    lat, lon = pgh.decode(geohash)
    poi_dict = {}  # place_id ã‚’ã‚­ãƒ¼ã«ã—ã¦POIã‚’ç®¡ç†
    
    print(f"  Geohash {geohash} (ç·¯åº¦: {lat:.5f}, çµŒåº¦: {lon:.5f}) ã®POIå–å¾—é–‹å§‹")
    
    # Grid Cellã‚’ä¿å­˜ã—ã¦IDã‚’å–å¾—
    grid_cell_id = save_grid_cell(geohash)
    if not grid_cell_id:
        print(f"    Grid Cellä¿å­˜å¤±æ•—ã®ãŸã‚ã€POIå–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return []
    
    for place_type in POI_TYPES.keys():
        pois = search_places_by_type(lat, lon, place_type)
        for poi in pois:
            place_id = poi.get('place_id')
            if not place_id:
                continue
                
            # POIã®ä½ç½®æƒ…å ±ã‚’å–å¾—
            poi_lat = poi.get('geometry', {}).get('location', {}).get('lat')
            poi_lng = poi.get('geometry', {}).get('location', {}).get('lng')
            
            if not poi_lat or not poi_lng:
                continue
                
            if place_id in poi_dict:
                # æ—¢å­˜POIã«ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ 
                existing_categories = set(poi_dict[place_id]['categories'])
                new_category = POI_TYPES[place_type]
                poi_dict[place_id]['categories'] = list(existing_categories.union({new_category}))
                print(f"    POI '{poi.get('name', 'Unknown')}' ã«ã‚«ãƒ†ã‚´ãƒª '{new_category}' ã‚’è¿½åŠ ")
            else:
                # æ–°ã—ã„POI
                point_wkt = f"POINT({poi_lng} {poi_lat})"
                poi_data = {
                    'id': place_id,  # Google Place IDã‚’ä¸»ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
                    'name': poi.get('name'),
                    'location': f"SRID=4326;{point_wkt}",  # PostGIS GEOMETRYå½¢å¼
                    'categories': [POI_TYPES[place_type]],  # JSONBé…åˆ—å½¢å¼
                    'grid_cell_id': grid_cell_id,  # å¤–éƒ¨ã‚­ãƒ¼
                    'rate': poi.get('rating', 0.0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤0.0
                }
                poi_dict[place_id] = poi_data
        
        # APIåˆ¶é™å¯¾ç­–
        time.sleep(1)
    
    all_pois = list(poi_dict.values())
    print(f"  Geohash {geohash}: {len(all_pois)}ä»¶ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯POIå–å¾—å®Œäº†")
    
    # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆã‚’å‡ºåŠ›
    category_stats = {}
    for poi in all_pois:
        for category in poi['categories']:
            category_stats[category] = category_stats.get(category, 0) + 1
    if category_stats:
        stats_str = ', '.join([f"{cat}:{count}" for cat, count in category_stats.items()])
        print(f"    ã‚«ãƒ†ã‚´ãƒªå†…è¨³: {stats_str}")
    
    return all_pois

def save_grid_cell(geohash):
    """Grid Cellã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    try:
        # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
        existing = supabase.table('grid_cells').select('id').eq('geohash', geohash).execute()
        if existing.data:
            grid_cell_id = existing.data[0]['id']
            print(f"    Grid Cell {geohash} ã¯æ—¢å­˜ (ID: {grid_cell_id})")
            return grid_cell_id
        
        # Geohashã‹ã‚‰ä¸­å¿ƒåº§æ¨™ã¨ãƒãƒªã‚´ãƒ³ã‚’å–å¾—
        lat, lon = pgh.decode(geohash)
        lat_err, lon_err = pgh.decode_exact(geohash)[1]
        
        # ãƒãƒªã‚´ãƒ³ã®å¢ƒç•Œã‚’è¨ˆç®—
        min_lat, max_lat = lat - lat_err, lat + lat_err
        min_lon, max_lon = lon - lon_err, lon + lon_err
        
        # PostGIS POLYGONå½¢å¼ã®WKTæ–‡å­—åˆ—ã‚’ä½œæˆ
        polygon_wkt = f"POLYGON(({min_lon} {min_lat}, {max_lon} {min_lat}, {max_lon} {max_lat}, {min_lon} {max_lat}, {min_lon} {min_lat}))"
        
        grid_cell_data = {
            'geometry': f"SRID=4326;{polygon_wkt}",
            'geohash': geohash
        }
        
        result = supabase.table('grid_cells').insert(grid_cell_data).execute()
        
        if result.data:
            grid_cell_id = result.data[0]['id']
            print(f"    Grid Cell {geohash} ä¿å­˜æˆåŠŸ (ID: {grid_cell_id})")
            return grid_cell_id
        else:
            print(f"    Grid Cell {geohash} ä¿å­˜å¤±æ•—")
            return None
            
    except Exception as e:
        print(f"    Grid Cell {geohash} ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def save_pois_to_db(pois):
    """POIã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆupsertæ©Ÿèƒ½ä½¿ç”¨ã€ã‚«ãƒ†ã‚´ãƒªãƒãƒ¼ã‚¸å¯¾å¿œï¼‰"""
    if not pois:
        return 0
    
    # POIã‚’place_idã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ã€è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã‚’ãƒãƒ¼ã‚¸
    poi_dict = {}
    for poi in pois:
        place_id = poi['id']
        if place_id in poi_dict:
            # æ—¢å­˜POIã«ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ 
            existing_categories = set(poi_dict[place_id]['categories'])
            new_categories = set(poi['categories'])
            poi_dict[place_id]['categories'] = list(existing_categories.union(new_categories))
        else:
            # æ–°ã—ã„POI
            poi_dict[place_id] = poi.copy()
    
    saved_count = 0
    
    for poi in poi_dict.values():
        try:
            # æ—¢å­˜POIã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã‚«ãƒ†ã‚´ãƒªã‚’ãƒãƒ¼ã‚¸
            existing = supabase.table('pois').select('id, categories').eq('id', poi['id']).execute()
            
            if existing.data:
                # æ—¢å­˜POIã®ã‚«ãƒ†ã‚´ãƒªã¨æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ãƒãƒ¼ã‚¸
                existing_categories = set(existing.data[0].get('categories', []))
                new_categories = set(poi['categories'])
                merged_categories = list(existing_categories.union(new_categories))
                poi['categories'] = merged_categories
                
                # upsertã§æ›´æ–°
                result = supabase.table('pois').upsert(
                    poi, 
                    on_conflict='id',
                    count='exact'
                ).execute()
                
                if result.data:
                    categories_str = ', '.join(poi['categories'])
                    print(f"    POI '{poi.get('name', 'Unknown')}' æ›´æ–°æˆåŠŸ (ã‚«ãƒ†ã‚´ãƒª: {categories_str})")
                    saved_count += 1
            else:
                # æ–°è¦æŒ¿å…¥
                result = supabase.table('pois').insert(poi).execute()
                
                if result.data:
                    categories_str = ', '.join(poi['categories'])
                    print(f"    POI '{poi.get('name', 'Unknown')}' æ–°è¦ä¿å­˜æˆåŠŸ (ã‚«ãƒ†ã‚´ãƒª: {categories_str})")
                    saved_count += 1
                    
        except Exception as e:
            print(f"    POIä¿å­˜ã‚¨ãƒ©ãƒ¼ ({poi.get('name', 'Unknown')}): {e}")
    
    return saved_count

def process_chunk(chunk_geohashes, chunk_index, total_chunks):
    """Geohashã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†"""
    print(f"\n=== ãƒãƒ£ãƒ³ã‚¯ {chunk_index + 1}/{total_chunks} é–‹å§‹ ===\n")
    print(f"å¯¾è±¡Geohash: {len(chunk_geohashes)}å€‹")
    
    chunk_start_time = datetime.now()
    total_pois_saved = 0
    
    for i, geohash in enumerate(chunk_geohashes):
        print(f"\n[{i+1}/{len(chunk_geohashes)}] å‡¦ç†ä¸­: {geohash}")
        
        # POIå–å¾—ï¼ˆGrid Cellä¿å­˜ã‚‚å«ã‚€ï¼‰
        pois = get_pois_for_geohash(geohash)
        
        # POIä¿å­˜
        saved_count = save_pois_to_db(pois)
        total_pois_saved += saved_count
        
        print(f"  POIä¿å­˜: {saved_count}ä»¶")
        
        # é€²æ—ä¿å­˜
        progress = {
            'current_chunk': chunk_index,
            'current_geohash_in_chunk': i + 1,
            'total_chunks': total_chunks,
            'chunk_geohashes': len(chunk_geohashes),
            'total_pois_saved_in_chunk': total_pois_saved,
            'last_processed_geohash': geohash,
            'timestamp': datetime.now().isoformat()
        }
        save_progress(progress)
    
    chunk_duration = datetime.now() - chunk_start_time
    print(f"\n=== ãƒãƒ£ãƒ³ã‚¯ {chunk_index + 1} å®Œäº† ===\n")
    print(f"å‡¦ç†æ™‚é–“: {chunk_duration}")
    print(f"POIä¿å­˜åˆè¨ˆ: {total_pois_saved}ä»¶")
    
    return total_pois_saved

def test_api_connections():
    """APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    print("=== APIæ¥ç¶šãƒ†ã‚¹ãƒˆ ===")
    
    # Google Places API (New) ãƒ†ã‚¹ãƒˆ
    test_lat, test_lon = 35.0116, 135.7681  # ç¥‡åœ’å››æ¡é§…ä»˜è¿‘
    url = "https://places.googleapis.com/v1/places:searchNearby"
    
    headers = {
        'Content-Type': 'application/json',
        'X-Goog-Api-Key': GOOGLE_MAPS_API_KEY,
        'X-Goog-FieldMask': 'places.id,places.displayName,places.rating'
    }
    
    payload = {
        "includedTypes": ["restaurant"],
        "maxResultCount": 3,
        "locationRestriction": {
            "circle": {
                "center": {
                    "latitude": test_lat,
                    "longitude": test_lon
                },
                "radius": 1000
            }
        },
        "languageCode": "ja",
        "regionCode": "JP"
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        places = data.get('places', [])
        if places:
            print(f"âœ… Google Places API (New): OK ({len(places)}ä»¶ã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã‚’å–å¾—)")
            sample_place = places[0]
            name = sample_place.get('displayName', {}).get('text', 'åå‰ãªã—')
            rating = sample_place.get('rating', 'ãªã—')
            print(f"   ã‚µãƒ³ãƒ—ãƒ«: {name} (è©•ä¾¡: {rating})")
        else:
            print(f"âš ï¸ Google Places API (New): ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆAPIã¯æ­£å¸¸ï¼‰")
    except Exception as e:
        print(f"âŒ Google Places API (New): æ¥ç¶šã‚¨ãƒ©ãƒ¼ - {e}")
        return False
    
    # Supabase æ¥ç¶šãƒ†ã‚¹ãƒˆ
    try:
        result = supabase.table('pois').select('id').limit(1).execute()
        print(f"âœ… Supabase: OK")
    except Exception as e:
        print(f"âŒ Supabase: æ¥ç¶šã‚¨ãƒ©ãƒ¼ - {e}")
        return False
    
    print("âœ… å…¨ã¦ã®APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼\n")
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = argparse.ArgumentParser(description='äº¬éƒ½POIå–å¾—ãƒ»ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ—ãƒ©ãƒ³3ï¼šç„¡æ–™æ æœ€å¤§åŒ–ç‰ˆï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿéš›ã®å®Ÿè¡Œã¯ã›ãšã€ãƒ†ã‚¹ãƒˆã®ã¿è¡Œã†')
    parser.add_argument('--test-only', action='store_true', help='APIæ¥ç¶šãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ')
    args = parser.parse_args()
    
    print("=== äº¬éƒ½POIå–å¾—ãƒ»ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ—ãƒ©ãƒ³3ï¼šç„¡æ–™æ æœ€å¤§åŒ–ç‰ˆï¼‰ ===\n")
    
    # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
    if not test_api_connections():
        print("âŒ APIæ¥ç¶šãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print("è©³ç´°ã¯ ../docs/google-places-api-setup.md ã‚’å‚ç…§")
        return
    
    # ãƒ†ã‚¹ãƒˆã®ã¿ã®å ´åˆã¯ã“ã“ã§çµ‚äº†
    if args.test_only:
        print("ğŸ¯ APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_plan3_config()
    all_geohashes = config['geohash_list']
    chunk_size = config['chunk_size']
    
    print(f"ç·Geohashæ•°: {len(all_geohashes)}å€‹")
    print(f"äºˆæƒ³POIæ•°: {config['estimated_pois']}ä»¶")
    print(f"äºˆæƒ³æ–™é‡‘: ${config['estimated_cost']:.0f}")
    
    # Dry-runãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
    if args.dry_run:
        print(f"\nğŸ§ª DRY-RUN ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®å®Ÿè¡Œã¯ã—ã¾ã›ã‚“ï¼‰")
        print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
        print(f"âœ… Geohashç”ŸæˆæˆåŠŸ: {len(all_geohashes)}å€‹")
        print(f"âœ… ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²: {len([all_geohashes[i:i+chunk_size] for i in range(0, len(all_geohashes), chunk_size)])}å€‹")
        print(f"âœ… APIæ¥ç¶šç¢ºèªæ¸ˆã¿")
        print(f"\nğŸ¯ å®Ÿéš›ã«å®Ÿè¡Œã™ã‚‹å ´åˆ:")
        print(f"   python script/kyoto_plan3_migration.py")
        return
    
    # é€²æ—ç¢ºèª
    progress = load_progress()
    start_chunk = 0
    if progress:
        print(f"\nå‰å›ã®é€²æ—ã‚’ç™ºè¦‹: ãƒãƒ£ãƒ³ã‚¯{progress['current_chunk'] + 1}ã¾ã§å®Œäº†")
        response = input("ç¶šãã‹ã‚‰å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if response.lower() == 'y':
            start_chunk = progress['current_chunk'] + 1
    
    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    chunks = [all_geohashes[i:i+chunk_size] for i in range(0, len(all_geohashes), chunk_size)]
    total_chunks = len(chunks)
    
    print(f"\nãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}å€‹")
    print(f"é–‹å§‹ãƒãƒ£ãƒ³ã‚¯: {start_chunk + 1}")
    
    # å®Ÿè¡Œç¢ºèª
    if start_chunk == 0:
        response = input("\næ–°è¦å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if response.lower() != 'y':
            print("å®Ÿè¡Œã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚")
            return
    
    # å®Ÿè¡Œé–‹å§‹
    overall_start_time = datetime.now()
    total_pois_overall = 0
    
    for chunk_index in range(start_chunk, total_chunks):
        chunk_pois = process_chunk(chunks[chunk_index], chunk_index, total_chunks)
        total_pois_overall += chunk_pois
        
        # ä¼‘æ†©ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
        if chunk_index < total_chunks - 1:
            print(f"\næ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã¾ã§30ç§’ä¼‘æ†©...")
            time.sleep(30)
    
    # å®Œäº†å ±å‘Š
    overall_duration = datetime.now() - overall_start_time
    print(f"\n\n=== å…¨å‡¦ç†å®Œäº† ===\n")
    print(f"ç·å‡¦ç†æ™‚é–“: {overall_duration}")
    print(f"ç·POIä¿å­˜æ•°: {total_pois_overall}ä»¶")
    print(f"ç·Geohashæ•°: {len(all_geohashes)}å€‹")
    print(f"å¹³å‡POI/Geohash: {total_pois_overall/len(all_geohashes):.1f}ä»¶")
    
    # æœ€çµ‚é€²æ—ã‚¯ãƒªã‚¢
    save_progress({
        'status': 'completed',
        'completed_at': datetime.now().isoformat(),
        'total_geohashes': len(all_geohashes),
        'total_pois': total_pois_overall,
        'total_duration': str(overall_duration)
    })

if __name__ == "__main__":
    main()
